\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\@writefile{toc}{\contentsline {section}{\numberline {1}The preference kernel}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Properties of the preference kernel}{1}{section.2}}
\citation{Minka2002,gerven2010a}
\citation{stern2009}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Analytic approximation to the binary entropy of the error function by a squared exponential. The absolute error is always smaller than $3 \cdot 10^{-3}$. }}{2}{figure.1}}
\newlabel{fig:trick}{{1}{2}{Analytic approximation to the binary entropy of the error function by a squared exponential. The absolute error is always smaller than $3 \cdot 10^{-3}$. \label {fig:trick}\relax }{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Taylor expansion on $\qopname  \relax o{log}\mathrm  {h}[\Phi (x)]$}{2}{section.3}}
\newlabel{sec:EPinference}{{4}{2}{Expectation propagation and variational Bayes\label {sec:EPinference}\relax }{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Expectation propagation and variational Bayes}{2}{section.4}}
\newlabel{eq:epPostApprox}{{5}{2}{Expectation propagation and variational Bayes\label {sec:EPinference}\relax }{equation.4.5}{}}
\citation{stern2009}
\citation{Bishop2007}
\citation{Minka2001}
\citation{Minka2002}
\newlabel{eq:KL}{{9}{3}{Expectation propagation and variational Bayes\label {sec:EPinference}\relax }{equation.4.9}{}}
\citation{HernandezLobato2010}
\newlabel{eq:damping}{{10}{4}{Expectation propagation and variational Bayes\label {sec:EPinference}\relax }{equation.4.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The EP predictive distribution}{4}{subsection.4.1}}
\newlabel{eq:predictiveMean}{{14}{4}{The EP predictive distribution\relax }{equation.4.14}{}}
\newlabel{eq:predictiveVariance}{{15}{4}{The EP predictive distribution\relax }{equation.4.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The EP update operations}{4}{subsection.4.2}}
\citation{stern2009}
\citation{raiko2007}
\newlabel{eq:Sigmah}{{24}{5}{The EP update operations\relax }{equation.4.24}{}}
\newlabel{eq:Sigma2h}{{25}{5}{The EP update operations\relax }{equation.4.25}{}}
\newlabel{eq:Sigmaw}{{28}{5}{The EP update operations\relax }{equation.4.28}{}}
\newlabel{eq:Sigma2w}{{29}{5}{The EP update operations\relax }{equation.4.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}The EP approximation of the model evidence}{6}{subsection.4.3}}
\newlabel{eq:Z3}{{49}{7}{The EP approximation of the model evidence\relax }{equation.4.49}{}}
\newlabel{eq:Z4}{{51}{7}{The EP approximation of the model evidence\relax }{equation.4.51}{}}
\citation{Minka2001,Minka2002}
\citation{snelson2006}
\citation{Guzman2007}
\citation{Lazaro2010}
\newlabel{eq:EPevidenceApprox}{{52}{8}{The EP approximation of the model evidence\relax }{equation.4.52}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Sparse approximations to speed up computations}{8}{subsection.4.4}}
\newlabel{sec:sparse}{{4.4}{8}{Sparse approximations to speed up computations\relax }{subsection.4.4}{}}
\citation{sebastiani2000}
\citation{freund1997}
\citation{lawrence2002}
\citation{tong2001}
\newlabel{eq:logZ3fitc}{{57}{9}{Sparse approximations to speed up computations\relax }{equation.4.57}{}}
\newlabel{eq:logZ4fitc}{{58}{9}{Sparse approximations to speed up computations\relax }{equation.4.58}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Performance of BALD on GP binary classification problems}{9}{section.5}}
\citation{sebastiani2000}
\citation{freund1997}
\citation{lawrence2002}
\citation{tong2001}
\newlabel{eqn:ent_change}{{61}{10}{Performance of BALD on GP binary classification problems\relax }{equation.5.61}{}}
\newlabel{eqn:rearrangement}{{62}{10}{Performance of BALD on GP binary classification problems\relax }{equation.5.62}{}}
\citation{Atteia1994315,Webster1994}
\citation{Kamishima05}
\citation{birlutiu2009}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance of BALD and other active learning algorithms on several binary classification datasets from the UCI repository. Entries indicate the number of datapoints (plus or minus one standard error of the mean) required to achieve $95\%$ of the predictive performance achieved by including the entire pool set. Bold typeface indicates the best performing algorithm for each dataset. N/A indicates that the corresponding algorithms did not meet the $95\%$ performance level by the end of the simulation. }}{11}{table.1}}
\newlabel{tab:activeTable}{{1}{11}{Performance of BALD and other active learning algorithms on several binary classification datasets from the UCI repository. Entries indicate the number of datapoints (plus or minus one standard error of the mean) required to achieve $95\%$ of the predictive performance achieved by including the entire pool set. Bold typeface indicates the best performing algorithm for each dataset. N/A indicates that the corresponding algorithms did not meet the $95\%$ performance level by the end of the simulation.\label {tab:activeTable} \relax }{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Detailed description of the analyzed datasets}{11}{section.6}}
\citation{Bonilla2010}
\@writefile{toc}{\contentsline {section}{\numberline {7}Model of Birlutiu et al.}{12}{section.7}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Model of Bonilla et al.}{12}{section.8}}
\newlabel{eq:covBonilla}{{64}{12}{Model of Bonilla et al}{equation.8.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Logarithm of the evidence returned by EP when run on the first training set of the experiments with synthetic data. Different values are considered for the lengthscale parameters $\sigma _\text  {users}$ and $\sigma _\text  {items}$. The synthetic data are generated using $\qopname  \relax o{log}\sigma _\text  {users} = 0$ and $\qopname  \relax o{log}\sigma _\text  {items} = 0$. The highest evidence returned by EP corresponds to values of $\qopname  \relax o{log}\sigma _\text  {users}$ and $\qopname  \relax o{log}\sigma _\text  {items}$ close to zero.}}{13}{figure.2}}
\newlabel{fig:experimentEvidence}{{2}{13}{Logarithm of the evidence returned by EP when run on the first training set of the experiments with synthetic data. Different values are considered for the lengthscale parameters $\sigma _\text {users}$ and $\sigma _\text {items}$. The synthetic data are generated using $\log \sigma _\text {users} = 0$ and $\log \sigma _\text {items} = 0$. The highest evidence returned by EP corresponds to values of $\log \sigma _\text {users}$ and $\log \sigma _\text {items}$ close to zero}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Average test error with 100 users.}}{13}{table.2}}
\newlabel{tab:errorSmallDatasets}{{2}{13}{Average test error with 100 users}{table.2}{}}
\newlabel{tab:small}{{2}{13}{Average test error with 100 users}{table.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Tuning the kernel lengthscale}{13}{section.9}}
\bibstyle{apalike}
\bibdata{bib/bibliog}
\bibcite{Atteia1994315}{{1}{1994}{{Atteia et~al.}}{{}}}
\bibcite{birlutiu2009}{{2}{2009}{{Birlutiu et~al.}}{{}}}
\bibcite{Bishop2007}{{3}{2007}{{Bishop}}{{}}}
\bibcite{Bonilla2010}{{4}{2010}{{Bonilla et~al.}}{{}}}
\bibcite{freund1997}{{5}{1997}{{Freund et~al.}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Test error for each method and active learning strategy with at most 1000 users.}}{14}{table.3}}
\newlabel{tab:large}{{3}{14}{Test error for each method and active learning strategy with at most 1000 users}{table.3}{}}
\newlabel{fig:learningcurves}{{9}{14}{Tuning the kernel lengthscale\relax }{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Average test error for CPU, CP and SU, using the strategies BALD (-B), entropy (-E) and random (-R) for active learning.}}{14}{figure.3}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Complete figures for active learning on large datasets}{14}{section.10}}
\bibcite{Lazaro2010}{{6}{2010}{{Gredilla}}{{}}}
\bibcite{HernandezLobato2010}{{7}{2010}{{Hern\'andez-Lobato}}{{}}}
\bibcite{Kamishima05}{{8}{2005}{{Kamishima et~al.}}{{}}}
\bibcite{lawrence2002}{{9}{2002}{{Lawrence et~al.}}{{}}}
\bibcite{Minka2001}{{10}{2001}{{Minka}}{{}}}
\bibcite{Minka2002}{{11}{2002}{{Minka and Lafferty}}{{}}}
\bibcite{Guzman2007}{{12}{2007}{{Naish-Guzman and Holden}}{{}}}
\bibcite{raiko2007}{{13}{2007}{{Raiko et~al.}}{{}}}
\bibcite{sebastiani2000}{{14}{2000}{{Sebastiani and Wynn}}{{}}}
\bibcite{snelson2006}{{15}{2005}{{Snelson and Ghahramani}}{{}}}
\bibcite{stern2009}{{16}{2009}{{Stern et~al.}}{{}}}
\bibcite{tong2001}{{17}{2001}{{Tong and Koller}}{{}}}
\bibcite{gerven2010a}{{18}{2010}{{van Gerven et~al.}}{{}}}
\bibcite{Webster1994}{{19}{1994}{{Webstet et~al.}}{{}}}
