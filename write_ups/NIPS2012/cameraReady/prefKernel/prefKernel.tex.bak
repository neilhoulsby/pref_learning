\section{A New View of Preference Learning}\label{sec:prefKernel}

We show that the problem of pairwise preference learning can be recast as a special case of binary classification.
Let us condider two items $i$ and $j$ with corresponding feature vectors $\mathbf{x}_i,\mathbf{x}_j\in\mathcal{X}$.
In the pairwise preference learning problem, we are given pairs of feature vectors $\mathbf{x}_i$ and $\mathbf{x}_j$
and corresponding class labels $y\in\{-1,1\}$ such that $y=1$ if the user prefers item $i$ to item $j$
and $y=-1$ otherwise. The task of interest is then to predict the class label for a new pair of feature vectors
not seen before. \citet{chu2005} 
address this problem by introducing a latent preference function $f:\mathcal{X}\mapsto \mathbb{R}$ such that
$f(\mathbf{x}_i) > f(\mathbf{x}_j)$ whenever the user prefers item $i$ to item $j$
and $f(\mathbf{x}_i) < f(\mathbf{x}_j)$ otherwise.
If we assume that the evaluations of $f$ are contaminated with independent Gaussian
noise with zero mean and variance $1/2$, we obtain the following likelihood function for $f$
given $\mathbf{x}_i$, $\mathbf{x}_j$ and $y$
\begin{align}
\mathcal{P}(y|\mathbf{x}_i,\mathbf{x}_j,f) &= \Phi[y(f[\mathbf{x}_i] - f[\mathbf{x}_j])]\,,\label{eq:likelihood}
\end{align}
where $\Phi$ is the standard Gaussian cumulative distribution function.
\citet{chu2005} solve the preference learning problem by combining a GP prior on $f$
with the likelihood function given by (\ref{eq:likelihood}). The posterior distribution for $f$ is
then used to make predictions on the user preferences.

Note that the likelihood function (\ref{eq:likelihood}) only depends on the difference between $f(\mathbf{x}_i)$ and $f(\mathbf{x}_j)$.
Let $g:\mathcal{X}^2\mapsto\mathbb{R}$ be the latent function $g(\mathbf{x}_i,\mathbf{x}_j) = f(\mathbf{x}_i) - f(\mathbf{x}_j)$.
We can recast the inference problem in terms of $g$ and ignore $f$. When the evaluation of $g$ is contaminated with standard Gaussian noise,
the likelihood for $g$ given $\mathbf{x}_i$, $\mathbf{x}_j$ and $y$ is
\begin{align}
\mathcal{P}(y|\mathbf{x}_i,\mathbf{x}_j,g) &= \Phi[yg(\mathbf{x}_i, \mathbf{x}_j)]\,.\label{eq:likelihood2}
\end{align}
Since $g$ is obtained from $f$ through a linear operation, the GP prior on $f$ induces a GP prior on $g$.
The mean function $\mu_{pref}$ and covariance function $k_{pref}$ of the GP prior on $g$ can be computed from the mean
function $\mu$ and covariance function $k$ of the GP on $f$ as follows
\begin{align}
& k_{pref}((\x_i,\x_j),(\x_k,\x_l)) = \notag\\ 
& \quad k(\x_i,\x_k) + k(\x_j,\x_l) - k(\x_i,\x_k) - k(\x_j,\x_l)\,,\\
&\mu_{pref}(\x_i,\x_j) = \mu(\x_i) - \mu(\x_j)\,.
\end{align}
The derivations can be found in the supplementary material.
We call $k_{pref}$ the \emph{preference kernel}.
The combination of (\ref{eq:likelihood2})
with a GP prior based on this new preference kernel allows us
to transform the problem of learning preferences into a
GP binary classification problem on the space of features
$\mathcal{X}^2$. 
This means that state-of-the art methods
for GP binary classification, such as expectation propagation,
can be trivially used for addressing pairwise preference learning problems.
Furthermore, the simplified likelihood (\ref{eq:likelihood2})
allows us to easily implement new sophisticated methods 
such as the following mutli-task approach.
