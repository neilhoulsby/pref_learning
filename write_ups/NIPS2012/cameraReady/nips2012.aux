\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{birlutiu2009}
\citation{brochu2007active}
\citation{de2009}
\citation{chu2005}
\citation{Bonilla2010}
\citation{birlutiu2009}
\citation{stern2009}
\citation{raiko2007}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{chu2005}
\citation{chu2005}
\citation{furnkranz2010}
\citation{Minka2001}
\citation{stern2009}
\citation{raiko2007}
\@writefile{toc}{\contentsline {section}{\numberline {2}Pairwise preference learning as special case of binary classification}{2}{section.2}}
\newlabel{sec:prefKernel}{{2}{2}{Pairwise preference learning as special case of binary classification\relax }{section.2}{}}
\newlabel{eq:likelihood}{{1}{2}{Pairwise preference learning as special case of binary classification\relax }{equation.2.1}{}}
\newlabel{eq:likelihood2}{{2}{2}{Pairwise preference learning as special case of binary classification\relax }{equation.2.2}{}}
\newlabel{sec:model}{{3}{2}{Multi-user preference learning \label {sec:model}\relax }{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Multi-user preference learning }{2}{section.3}}
\newlabel{eq:expressionG}{{3}{2}{Multi-user preference learning \label {sec:model}\relax }{equation.3.3}{}}
\citation{Minka2001}
\citation{Ghahramani2001}
\citation{nickisch2008}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Probabilistic description}{3}{subsection.3.1}}
\newlabel{eq:priorW}{{4}{3}{Probabilistic description\relax }{equation.3.4}{}}
\newlabel{eq:priorH}{{5}{3}{Probabilistic description\relax }{equation.3.5}{}}
\newlabel{eq:post}{{6}{3}{Probabilistic description\relax }{equation.3.6}{}}
\newlabel{eq:predictions}{{7}{3}{Probabilistic description\relax }{equation.3.7}{}}
\newlabel{eq:predictive}{{8}{3}{Probabilistic description\relax }{equation.3.8}{}}
\citation{brochu2007active}
\citation{lindley1956}
\citation{mackay1992}
\citation{lawrence2002}
\citation{mackay1992}
\citation{krishnapuram2004}
\citation{lawrence2002}
\newlabel{SC@1}{{4.1}{4}{BALD in binary classification with GPs\relax }{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Toy example with 1D input. Circles and crosses denote labelled data. The plot shows the mean and variance of the GP predictive distribution. Maximum Entropy Sampling (MES) samples from the region of highest marginal uncertainty, ignoring the second term in \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eqn:rearrangement}\unskip \@@italiccorr )}}. BALD samples from the region of greatest uncertainty in the latent function.}}{4}{figure.1}}
\newlabel{fig:BALD}{{1}{4}{\SC@CAPtext \relax }{figure.1}{}}
\newlabel{sec:active}{{4}{4}{Bayesian active learning by disagreement\label {sec:active}\relax }{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Bayesian active learning by disagreement}{4}{section.4}}
\newlabel{eqn:ent_change}{{9}{4}{Bayesian active learning by disagreement\label {sec:active}\relax }{equation.4.9}{}}
\newlabel{eqn:rearrangement}{{10}{4}{Bayesian active learning by disagreement\label {sec:active}\relax }{equation.4.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}BALD in binary classification with GPs}{4}{subsection.4.1}}
\citation{sebastiani2000}
\citation{Minka2002}
\citation{Ghahramani2001}
\citation{stern2009}
\newlabel{eqn:BALD}{{11}{5}{BALD in binary classification with GPs\relax }{equation.4.11}{}}
\newlabel{sec:EPinference}{{5}{5}{Expectation propagation and variational Bayes \label {sec:EPinference}\relax }{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Expectation propagation and variational Bayes }{5}{section.5}}
\citation{Snelson2006}
\citation{birlutiu2009}
\citation{Bonilla2010}
\citation{MacKay2001}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}A sparse approximation to speed up computation}{6}{subsection.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments and Discussion}{6}{section.6}}
\newlabel{sec:experiments}{{6}{6}{Experiments and Discussion\relax }{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Comparison with other multi-user methods}{6}{subsection.6.1}}
\@writefile{toc}{\contentsline {paragraph}{Alternative models.}{6}{section*.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average test error with 100 users.}}{7}{table.1}}
\newlabel{tab:errorSmallDatasets}{{1}{7}{Average test error with 100 users}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Training times (s) with 100 users.}}{7}{table.2}}
\newlabel{tab:timeSmallDatasets}{{2}{7}{Training times (s) with 100 users}{table.2}{}}
\newlabel{tab:small}{{6.1}{7}{Experimental procedure}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Test error for each method and active learning strategy with at most 1000 users.}}{7}{table.3}}
\newlabel{tab:large}{{3}{7}{Test error for each method and active learning strategy with at most 1000 users}{table.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Experimental procedure.}{7}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{Results.}{7}{section*.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Active learning on large datasets}{7}{subsection.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Average test error for CPU, CP and SU, using the strategies BALD (-B), entropy (-E) and random (-R) for active learning. For clarity, the curves for CPU are included only in the Synthetic and Election datasets. The complete plots can be found in Section 10 of the supplementary material.}}{8}{figure.2}}
\newlabel{fig:learningcurves}{{2}{8}{Average test error for CPU, CP and SU, using the strategies BALD (-B), entropy (-E) and random (-R) for active learning. For clarity, the curves for CPU are included only in the Synthetic and Election datasets. The complete plots can be found in Section 10 of the supplementary material.\label {fig:learningcurves}\relax }{figure.2}{}}
\newlabel{sec:conclusions}{{7}{8}{Conclusions\label {sec:conclusions}\relax }{section.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{8}{section.7}}
\bibdata{bib/bibliog}
\bibcite{birlutiu2009}{1}
\bibcite{Bonilla2010}{2}
\bibcite{brochu2007active}{3}
\bibcite{chu2005}{4}
\bibcite{de2009}{5}
\bibcite{furnkranz2010}{6}
\bibcite{Ghahramani2001}{7}
\bibcite{krishnapuram2004}{8}
\bibcite{lawrence2002}{9}
\bibcite{lindley1956}{10}
\bibcite{MacKay2001}{11}
\bibcite{mackay1992}{12}
\bibcite{Minka2002}{13}
\bibcite{Minka2001}{14}
\bibcite{nickisch2008}{15}
\bibcite{raiko2007}{16}
\bibcite{sebastiani2000}{17}
\bibcite{Snelson2006}{18}
\bibcite{stern2009}{19}
\bibstyle{plain}
