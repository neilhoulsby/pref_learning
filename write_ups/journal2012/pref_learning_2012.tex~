% TODO:
% 1. any more experiments? an interpretation of the weights? missing single features?
% 2. discuss any of the points that the NIPS reviewers brought up?
% 3. future work

\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{bm}
\usepackage{natbib}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{fixltx2e}
\usepackage{dblfloatfix}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{subfigure} 
\usepackage{hyperref}
\usepackage{comment}
\usepackage{gensymb}

\newcommand{\argmax}{ \operatorname*{arg \max}}
\newcommand{\argmin}{ \operatorname*{arg \min}} 
\newcommand{\x}{\mathbf{x}} 
\newcommand{\pair}{(\x,\x')} 
\newcommand{\param}{\bm{\theta}}
\newcommand{\X}{\mathbf{X}} 
\newcommand{\y}{y}
\newcommand{\data}{\mathcal{D}} 
\newcommand{\h}{\mathbf{H}} 
\newcommand{\g}{\mathbf{G}} 
\newcommand{\w}{\mathbf{W}} 
\newcommand{\pr}{\mathrm{P}} 
\newcommand{\ent}{\mathrm{H}} 
\newcommand{\info}{\mathrm{I}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\T}{\mathrm{T}}
\newcommand{\ie}{i.\,e.\ }
\newcommand{\eg}{e.\,g.\ }
\newcommand{\latfun}{f}
\newcommand{\List}{\mathcal{L}}

\begin{document}

\title{Collaborative Gaussian Processes for Preference Learning}

\date{15/01/2012}

\author{Jose Miguel Hern\'{a}ndez-Lobato \\ University of Cambridge \\ \texttt{jmh233@cam.ac.uk} \and Neil Houlsby \\ University of Cambridge  \\ \texttt{nmth2@cam.ac.uk} \and Ferenc Husz\'{a}r \\ University of Cambridge \\ \texttt{fh277@cam.ac.uk} \and Zoubin Ghahramani \\ University of Cambridge \\ \texttt{zoubin@eng.cam.ac.uk}}
\maketitle

\begin{abstract}
We present a new model based on Gaussian processes (GPs) for learning pairwise preferences expressed by multiple users.
Our approach combines supervised GP learning of user preferences with unsupervised dimensionality
reduction techniques for multi-user systems. 
The model not only exploits collaborative information from
the shared structure in user behavior, but may also incorporate user features if they are available. 
We introduce the \emph{preference kernel} which simplifies inference in this domain,
allowing us to perform approximate inference using a combination of
expectation propagation and variational Bayes. 
Finally, in real-world applications it is desirable to learn the model from minimal supervised data, for this purpose we present an efficient active learning strategy for querying preferences.
The proposed model and active learning performs favorably on real-world data against state-of-the-art multi-user preference learning algorithms.
\end{abstract}

\input{introduction/introduction}
\input{prefKernel/prefKernel.tex}
\input{model/model.tex}
\input{activeLearning/active.tex}
\input{ep/ep.tex}
\input{relatedWork/related.tex}
\input{experiments/experiments.tex}
\input{conclusions/conclusions.tex}

{
\bibliographystyle{apalike}
\bibliography{bib/bibliog}
}

\newpage

\end{document}
