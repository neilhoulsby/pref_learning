Creating subfolder 1

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.0804
[1] 1.232503
[1] 1.225992
[1] 1.125628
[1] 1.059464
[1] 0.9854394
[1] 0.9173263
[1] 0.8603306
[1] 0.8131177
[1] 0.7745449
[1] 0.742812
[1] 0.7161201
[1] 0.6932076
[1] 0.6734733
[1] 0.6608233
[1] 0.6492337
[1] 0.6384554
[1] 0.6281531
[1] 0.6184009
[1] 1
> 
Creating subfolder 2

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.19316
[1] 1.393401
[1] 1.371633
[1] 1.250353
[1] 1.127667
[1] 1.036807
[1] 0.9934323
[1] 0.9645777
[1] 0.9454968
[1] 0.9324916
[1] 0.9196038
[1] 0.9072699
[1] 0.8949147
[1] 0.8828277
[1] 0.8712765
[1] 0.8603309
[1] 0.8504792
[1] 0.841036
[1] 0.8323847
[1] 1
> 
Creating subfolder 3

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.083245
[1] 1.23574
[1] 1.197894
[1] 1.068163
[1] 0.935851
[1] 0.8338256
[1] 0.7629416
[1] 0.7141073
[1] 0.6797138
[1] 0.6543517
[1] 0.6354213
[1] 0.6205722
[1] 0.6088272
[1] 0.5991721
[1] 0.5914717
[1] 0.5853989
[1] 0.5803095
[1] 0.5761511
[1] 0.5730392
[1] 1
> 
Creating subfolder 4

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.335575
[1] 1.58285
[1] 1.642332
[1] 1.566064
[1] 1.442724
[1] 1.326929
[1] 1.233897
[1] 1.163037
[1] 1.108435
[1] 1.065318
[1] 1.03056
[1] 1.001603
[1] 0.9770064
[1] 0.9561927
[1] 0.9382889
[1] 0.9228663
[1] 0.910194
[1] 0.898869
[1] 0.8894958
[1] 1
> 
Creating subfolder 5

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.100074
[1] 1.273466
[1] 1.264238
[1] 1.153885
[1] 1.027905
[1] 0.9261527
[1] 0.853806
[1] 0.8045737
[1] 0.7706492
[1] 0.7472251
[1] 0.7296289
[1] 0.7163213
[1] 0.7061296
[1] 0.6976328
[1] 0.6910219
[1] 0.6855402
[1] 0.680404
[1] 0.6762174
[1] 0.6727013
[1] 1
> 
Creating subfolder 6

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.117371
[1] 1.346675
[1] 1.365704
[1] 1.255612
[1] 1.115711
[1] 0.9959978
[1] 0.9075605
[1] 0.8443268
[1] 0.7991056
[1] 0.7654879
[1] 0.7387441
[1] 0.7164085
[1] 0.697194
[1] 0.6804113
[1] 0.6647779
[1] 0.650703
[1] 0.6373179
[1] 0.6248404
[1] 0.6132205
[1] 1
> 
Creating subfolder 7

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.297849
[1] 1.54301
[1] 1.579489
[1] 1.47244
[1] 1.316705
[1] 1.178638
[1] 1.074784
[1] 1.000148
[1] 0.9459524
[1] 0.9046967
[1] 0.8718302
[1] 0.8462964
[1] 0.82461
[1] 0.8049534
[1] 0.7869823
[1] 0.7703702
[1] 0.7551369
[1] 0.74039
[1] 0.7262613
[1] 1
> 
Creating subfolder 8

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 0.9384224
[1] 1.101505
[1] 1.113442
[1] 1.031276
[1] 0.9282207
[1] 0.8530998
[1] 0.7960512
[1] 0.7515292
[1] 0.7170631
[1] 0.6901028
[1] 0.6684635
[1] 0.650635
[1] 0.636971
[1] 0.6288072
[1] 0.6219108
[1] 0.6160057
[1] 0.6105877
[1] 0.6056929
[1] 0.6009913
[1] 1
> 
Creating subfolder 9

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.476044
[1] 1.670782
[1] 1.615094
[1] 1.431899
[1] 1.247615
[1] 1.118423
[1] 1.045749
[1] 0.9826564
[1] 0.9295115
[1] 0.8851684
[1] 0.8482377
[1] 0.8176074
[1] 0.7923152
[1] 0.7737182
[1] 0.7613956
[1] 0.7513067
[1] 0.7423333
[1] 0.7343309
[1] 0.7275274
[1] 1
> 
Creating subfolder 10

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 0.990725
[1] 1.111281
[1] 1.116241
[1] 1.037829
[1] 0.9459428
[1] 0.8929948
[1] 0.8416864
[1] 0.7949774
[1] 0.7544248
[1] 0.7198795
[1] 0.6908819
[1] 0.6667253
[1] 0.6465343
[1] 0.6293717
[1] 0.6147614
[1] 0.6017109
[1] 0.5902317
[1] 0.579941
[1] 0.5709108
[1] 1
> 
Creating subfolder 11

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.168107
[1] 1.368463
[1] 1.381191
[1] 1.264347
[1] 1.123438
[1] 1.007729
[1] 0.9258649
[1] 0.8702761
[1] 0.8319937
[1] 0.8048138
[1] 0.7844862
[1] 0.768434
[1] 0.7552785
[1] 0.7443653
[1] 0.7351309
[1] 0.7276057
[1] 0.7212829
[1] 0.7161553
[1] 0.71225
[1] 1
> 
Creating subfolder 12

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.094917
[1] 1.298051
[1] 1.386004
[1] 1.333577
[1] 1.222662
[1] 1.108815
[1] 1.014317
[1] 0.94308
[1] 0.8866068
[1] 0.8415638
[1] 0.8068389
[1] 0.7785719
[1] 0.7551628
[1] 0.7350831
[1] 0.7174414
[1] 0.7020107
[1] 0.6874774
[1] 0.6742769
[1] 0.6621633
[1] 1
> 
Creating subfolder 13

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.253167
[1] 1.536216
[1] 1.61023
[1] 1.506685
[1] 1.336537
[1] 1.192653
[1] 1.104041
[1] 1.034621
[1] 0.9802891
[1] 0.9367097
[1] 0.9012173
[1] 0.8711705
[1] 0.8451821
[1] 0.8224679
[1] 0.8024609
[1] 0.7844625
[1] 0.7683772
[1] 0.7537464
[1] 0.7399555
[1] 1
> 
Creating subfolder 14

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.188456
[1] 1.349179
[1] 1.341555
[1] 1.209189
[1] 1.056101
[1] 0.9308787
[1] 0.841927
[1] 0.7814992
[1] 0.7411318
[1] 0.7135087
[1] 0.6940419
[1] 0.6799911
[1] 0.66984
[1] 0.6616354
[1] 0.6556
[1] 0.6502716
[1] 0.6457582
[1] 0.6419345
[1] 0.6384884
[1] 1
> 
Creating subfolder 15

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.193871
[1] 1.395346
[1] 1.360323
[1] 1.210224
[1] 1.05535
[1] 0.9370563
[1] 0.85573
[1] 0.8014024
[1] 0.7642032
[1] 0.7379264
[1] 0.7183271
[1] 0.7033721
[1] 0.691868
[1] 0.6820972
[1] 0.6738331
[1] 0.6667
[1] 0.6600402
[1] 0.6539928
[1] 0.6481275
[1] 1
> 
Creating subfolder 16

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.251494
[1] 1.42864
[1] 1.402593
[1] 1.260773
[1] 1.110323
[1] 0.9974621
[1] 0.9169925
[1] 0.8610645
[1] 0.8213692
[1] 0.7916765
[1] 0.7684235
[1] 0.7491074
[1] 0.7324621
[1] 0.7176538
[1] 0.704837
[1] 0.6933039
[1] 0.6827916
[1] 0.6732155
[1] 0.6644335
[1] 1
> 
Creating subfolder 17

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.055802
[1] 1.279555
[1] 1.307612
[1] 1.208335
[1] 1.076461
[1] 0.9643039
[1] 0.89742
[1] 0.8489822
[1] 0.8128078
[1] 0.7841558
[1] 0.761339
[1] 0.7426062
[1] 0.7308866
[1] 0.7201557
[1] 0.7103275
[1] 0.7011864
[1] 0.6929018
[1] 0.6855408
[1] 0.6789045
[1] 1
> 
Creating subfolder 18

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 0.9506463
[1] 1.138182
[1] 1.156614
[1] 1.069112
[1] 0.9544498
[1] 0.8837362
[1] 0.8282285
[1] 0.7812691
[1] 0.7431021
[1] 0.7124968
[1] 0.6880685
[1] 0.6680704
[1] 0.6516488
[1] 0.6378031
[1] 0.6260832
[1] 0.6200705
[1] 0.6142421
[1] 0.6092805
[1] 0.6042691
[1] 1
> 
Creating subfolder 19

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.29332
[1] 1.532294
[1] 1.576696
[1] 1.477137
[1] 1.335046
[1] 1.209261
[1] 1.113992
[1] 1.04517
[1] 0.9932424
[1] 0.9536425
[1] 0.9215431
[1] 0.8940021
[1] 0.8695273
[1] 0.8476185
[1] 0.8278503
[1] 0.8095394
[1] 0.7929041
[1] 0.7771135
[1] 0.762896
[1] 1
> 
Creating subfolder 20

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.271124
[1] 1.495329
[1] 1.523349
[1] 1.420904
[1] 1.288841
[1] 1.188466
[1] 1.120122
[1] 1.073978
[1] 1.043766
[1] 1.023338
[1] 1.008684
[1] 0.9975292
[1] 0.9880432
[1] 0.9788512
[1] 0.9704541
[1] 0.962434
[1] 0.9543471
[1] 0.946637
[1] 0.9384702
[1] 1
> 
Creating subfolder 21

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 0.9853764
[1] 1.168827
[1] 1.260162
[1] 1.254529
[1] 1.197785
[1] 1.131181
[1] 1.071389
[1] 1.02229
[1] 0.9822568
[1] 0.9491773
[1] 0.9213215
[1] 0.8972994
[1] 0.8761349
[1] 0.8571651
[1] 0.8400434
[1] 0.8247501
[1] 0.8108934
[1] 0.7986824
[1] 0.7878005
[1] 1
> 
Creating subfolder 22

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.30359
[1] 1.4384
[1] 1.380757
[1] 1.218758
[1] 1.063491
[1] 0.9501632
[1] 0.8741352
[1] 0.8231508
[1] 0.7879172
[1] 0.7621818
[1] 0.7418961
[1] 0.7250027
[1] 0.7102386
[1] 0.6971088
[1] 0.6850746
[1] 0.6738693
[1] 0.6630602
[1] 0.6526998
[1] 0.6428333
[1] 1
> 
Creating subfolder 23

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.22386
[1] 1.415477
[1] 1.408793
[1] 1.296234
[1] 1.147644
[1] 1.017578
[1] 0.9191679
[1] 0.8471391
[1] 0.7947762
[1] 0.755733
[1] 0.7257641
[1] 0.7018294
[1] 0.6821855
[1] 0.6662617
[1] 0.6526954
[1] 0.6415424
[1] 0.6316687
[1] 0.6232865
[1] 0.6156453
[1] 1
> 
Creating subfolder 24

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.311275
[1] 1.618579
[1] 1.655998
[1] 1.532179
[1] 1.376765
[1] 1.249579
[1] 1.182099
[1] 1.126326
[1] 1.078199
[1] 1.036656
[1] 1.000759
[1] 0.9707115
[1] 0.9519917
[1] 0.9355121
[1] 0.9213331
[1] 0.9090807
[1] 0.8983295
[1] 0.8890214
[1] 0.8812929
[1] 1
> 
Creating subfolder 25

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.332208
[1] 1.512309
[1] 1.443571
[1] 1.25985
[1] 1.080096
[1] 0.9457509
[1] 0.8536893
[1] 0.7910627
[1] 0.7472623
[1] 0.7150485
[1] 0.6904609
[1] 0.6706204
[1] 0.6546685
[1] 0.6414992
[1] 0.6303798
[1] 0.6209847
[1] 0.6131819
[1] 0.6062447
[1] 0.6005383
[1] 1
> 
Creating subfolder 1
mkdir: cannot create directory `simulation1': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.0804
[1] 1.232503
[1] 1.225992
[1] 1.125628
[1] 1.059464
[1] 0.9854394
[1] 0.9173263
[1] 0.8603306
[1] 0.8131177
[1] 0.7745449
[1] 0.742812
[1] 0.7161201
[1] 0.6932076
[1] 0.6734733
[1] 0.6608233
[1] 0.6492337
[1] 0.6384554
[1] 0.6281531
[1] 0.6184009
[1] 0.6092388
[1] 0.6006065
[1] 0.5923574
[1] 0.5848813
[1] 0.5778432
[1] 0.5711522
[1] 0.5646879
[1] 0.5586457
[1] 0.5531867
[1] 0.5479178
[1] 0.5428633
[1] 0.5379182
[1] 0.5333791
[1] 0.5290223
[1] 0.5245608
[1] 0.5204215
[1] 0.516495
[1] 0.5126954
[1] 0.5089602
[1] 0.5054424
[1] 1
> 
Creating subfolder 2
mkdir: cannot create directory `simulation2': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.19316
[1] 1.393401
[1] 1.371633
[1] 1.250353
[1] 1.127667
[1] 1.036807
[1] 0.9934323
[1] 0.9645777
[1] 0.9454968
[1] 0.9324916
[1] 0.9196038
[1] 0.9072699
[1] 0.8949147
[1] 0.8828277
[1] 0.8712765
[1] 0.8603309
[1] 0.8504792
[1] 0.841036
[1] 0.8323847
[1] 0.8243176
[1] 0.8171542
[1] 0.8104577
[1] 0.8040818
[1] 0.7982289
[1] 0.7929882
[1] 0.7880009
[1] 0.7832411
[1] 0.7787321
[1] 0.7752738
[1] 0.7720854
[1] 0.7695862
[1] 0.766741
[1] 0.7641203
[1] 0.761862
[1] 0.7600383
[1] 0.7578874
[1] 0.7560713
[1] 0.754384
[1] 0.7528416
[1] 1
> 
Creating subfolder 3
mkdir: cannot create directory `simulation3': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.083245
[1] 1.23574
[1] 1.197894
[1] 1.068163
[1] 0.935851
[1] 0.8338256
[1] 0.7629416
[1] 0.7141073
[1] 0.6797138
[1] 0.6543517
[1] 0.6354213
[1] 0.6205722
[1] 0.6088272
[1] 0.5991721
[1] 0.5914717
[1] 0.5853989
[1] 0.5803095
[1] 0.5761511
[1] 0.5730392
[1] 0.5705857
[1] 0.5690262
[1] 0.5679925
[1] 0.5673174
[1] 0.5669635
[1] 0.5669506
[1] 0.5673772
[1] 0.5681287
[1] 0.5691344
[1] 0.5700965
[1] 0.5713104
[1] 0.5725509
[1] 0.5740162
[1] 0.5753754
[1] 0.5767726
[1] 0.5780166
[1] 0.5792857
[1] 0.5804827
[1] 0.5817006
[1] 0.582815
[1] 1
> 
Creating subfolder 4
mkdir: cannot create directory `simulation4': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.335575
[1] 1.58285
[1] 1.642332
[1] 1.566064
[1] 1.442724
[1] 1.326929
[1] 1.233897
[1] 1.163037
[1] 1.108435
[1] 1.065318
[1] 1.03056
[1] 1.001603
[1] 0.9770064
[1] 0.9561927
[1] 0.9382889
[1] 0.9228663
[1] 0.910194
[1] 0.898869
[1] 0.8894958
[1] 0.8820582
[1] 0.8758703
[1] 0.870731
[1] 0.8669763
[1] 0.8641608
[1] 0.8620642
[1] 0.8609191
[1] 0.8603687
[1] 0.8604525
[1] 0.8608815
[1] 0.8617436
[1] 0.8630955
[1] 0.864557
[1] 0.8661394
[1] 0.8677228
[1] 0.8695163
[1] 0.8715032
[1] 0.8733551
[1] 0.8754578
[1] 0.8773223
[1] 1
> 
Creating subfolder 5
mkdir: cannot create directory `simulation5': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.100074
[1] 1.273466
[1] 1.264238
[1] 1.153885
[1] 1.027905
[1] 0.9261527
[1] 0.853806
[1] 0.8045737
[1] 0.7706492
[1] 0.7472251
[1] 0.7296289
[1] 0.7163213
[1] 0.7061296
[1] 0.6976328
[1] 0.6910219
[1] 0.6855402
[1] 0.680404
[1] 0.6762174
[1] 0.6727013
[1] 0.6694192
[1] 0.6663327
[1] 0.6636008
[1] 0.6612576
[1] 0.6591617
[1] 0.6572078
[1] 0.6552312
[1] 0.6532759
[1] 0.6514321
[1] 0.649721
[1] 0.6478883
[1] 0.6464261
[1] 0.6446704
[1] 0.6430245
[1] 0.641525
[1] 0.6400675
[1] 0.6386676
[1] 0.6374302
[1] 0.6364335
[1] 0.6352744
[1] 1
> 
Creating subfolder 6
mkdir: cannot create directory `simulation6': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.117371
[1] 1.346675
[1] 1.365704
[1] 1.255612
[1] 1.115711
[1] 0.9959978
[1] 0.9075605
[1] 0.8443268
[1] 0.7991056
[1] 0.7654879
[1] 0.7387441
[1] 0.7164085
[1] 0.697194
[1] 0.6804113
[1] 0.6647779
[1] 0.650703
[1] 0.6373179
[1] 0.6248404
[1] 0.6132205
[1] 0.6021482
[1] 0.5920162
[1] 0.5825213
[1] 0.5737717
[1] 0.5654166
[1] 0.5576274
[1] 0.55047
[1] 0.5439386
[1] 0.5379132
[1] 0.5321404
[1] 0.5268386
[1] 0.5218459
[1] 0.5171188
[1] 0.512815
[1] 0.5087117
[1] 0.5046952
[1] 0.5011205
[1] 0.4977528
[1] 0.4947444
[1] 0.4916373
[1] 1
> 
Creating subfolder 7
mkdir: cannot create directory `simulation7': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.297849
[1] 1.54301
[1] 1.579489
[1] 1.47244
[1] 1.316705
[1] 1.178638
[1] 1.074784
[1] 1.000148
[1] 0.9459524
[1] 0.9046967
[1] 0.8718302
[1] 0.8462964
[1] 0.82461
[1] 0.8049534
[1] 0.7869823
[1] 0.7703702
[1] 0.7551369
[1] 0.74039
[1] 0.7262613
[1] 0.7131169
[1] 0.7004603
[1] 0.6884453
[1] 0.6769858
[1] 0.665738
[1] 0.655192
[1] 0.6452782
[1] 0.635806
[1] 0.6270497
[1] 0.6189393
[1] 0.6112604
[1] 0.6042919
[1] 0.5978264
[1] 0.5918053
[1] 0.5866339
[1] 0.5815561
[1] 0.5771423
Creating subfolder 1
mkdir: cannot create directory `simulation1': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.0804
[1] 1.232503
[1] 1.225992
[1] 1.125628
[1] 1.059464
[1] 0.9854394
[1] 0.9173263
[1] 0.8603306
[1] 0.8131177
[1] 0.7745449
[1] 0.742812
[1] 0.7161201
[1] 0.6932076
[1] 0.6734733
[1] 0.6608233
[1] 0.6492337
[1] 0.6384554
[1] 0.6281531
[1] 0.6184009
[1] 1
> 
Creating subfolder 2
mkdir: cannot create directory `simulation2': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.19316
[1] 1.393401
[1] 1.371633
[1] 1.250353
[1] 1.127667
[1] 1.036807
[1] 0.9934323
[1] 0.9645777
[1] 0.9454968
[1] 0.9324916
[1] 0.9196038
[1] 0.9072699
[1] 0.8949147
[1] 0.8828277
[1] 0.8712765
[1] 0.8603309
[1] 0.8504792
[1] 0.841036
[1] 0.8323847
[1] 1
> 
Creating subfolder 3
mkdir: cannot create directory `simulation3': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.083245
[1] 1.23574
[1] 1.197894
[1] 1.068163
[1] 0.935851
[1] 0.8338256
[1] 0.7629416
[1] 0.7141073
[1] 0.6797138
[1] 0.6543517
[1] 0.6354213
[1] 0.6205722
[1] 0.6088272
[1] 0.5991721
[1] 0.5914717
[1] 0.5853989
[1] 0.5803095
[1] 0.5761511
[1] 0.5730392
[1] 1
> 
Creating subfolder 4
mkdir: cannot create directory `simulation4': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.335575
[1] 1.58285
[1] 1.642332
[1] 1.566064
[1] 1.442724
[1] 1.326929
[1] 1.233897
[1] 1.163037
[1] 1.108435
[1] 1.065318
[1] 1.03056
[1] 1.001603
[1] 0.9770064
[1] 0.9561927
[1] 0.9382889
[1] 0.9228663
[1] 0.910194
[1] 0.898869
[1] 0.8894958
[1] 1
> 
Creating subfolder 5
mkdir: cannot create directory `simulation5': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.100074
[1] 1.273466
[1] 1.264238
[1] 1.153885
[1] 1.027905
[1] 0.9261527
[1] 0.853806
[1] 0.8045737
[1] 0.7706492
[1] 0.7472251
[1] 0.7296289
[1] 0.7163213
[1] 0.7061296
[1] 0.6976328
[1] 0.6910219
[1] 0.6855402
[1] 0.680404
[1] 0.6762174
[1] 0.6727013
[1] 1
> 
Creating subfolder 6
mkdir: cannot create directory `simulation6': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.117371
[1] 1.346675
[1] 1.365704
[1] 1.255612
[1] 1.115711
[1] 0.9959978
[1] 0.9075605
[1] 0.8443268
[1] 0.7991056
[1] 0.7654879
[1] 0.7387441
[1] 0.7164085
[1] 0.697194
[1] 0.6804113
[1] 0.6647779
[1] 0.650703
[1] 0.6373179
[1] 0.6248404
[1] 0.6132205
[1] 1
> 
Creating subfolder 7
mkdir: cannot create directory `simulation7': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.297849
[1] 1.54301
[1] 1.579489
[1] 1.47244
[1] 1.316705
[1] 1.178638
[1] 1.074784
[1] 1.000148
[1] 0.9459524
[1] 0.9046967
[1] 0.8718302
[1] 0.8462964
[1] 0.82461
[1] 0.8049534
[1] 0.7869823
[1] 0.7703702
[1] 0.7551369
[1] 0.74039
[1] 0.7262613
[1] 1
> 
Creating subfolder 8
mkdir: cannot create directory `simulation8': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 0.9384224
[1] 1.101505
[1] 1.113442
[1] 1.031276
[1] 0.9282207
[1] 0.8530998
[1] 0.7960512
[1] 0.7515292
[1] 0.7170631
[1] 0.6901028
[1] 0.6684635
[1] 0.650635
[1] 0.636971
[1] 0.6288072
[1] 0.6219108
[1] 0.6160057
[1] 0.6105877
[1] 0.6056929
[1] 0.6009913
[1] 1
> 
Creating subfolder 9
mkdir: cannot create directory `simulation9': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.476044
[1] 1.670782
[1] 1.615094
[1] 1.431899
[1] 1.247615
[1] 1.118423
[1] 1.045749
[1] 0.9826564
[1] 0.9295115
[1] 0.8851684
[1] 0.8482377
[1] 0.8176074
[1] 0.7923152
[1] 0.7737182
[1] 0.7613956
[1] 0.7513067
[1] 0.7423333
[1] 0.7343309
[1] 0.7275274
[1] 1
> 
Creating subfolder 10
mkdir: cannot create directory `simulation10': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 0.990725
[1] 1.111281
[1] 1.116241
[1] 1.037829
[1] 0.9459428
[1] 0.8929948
./createFolders.sh: line 4: 30181 Killed                  nice -18 /home/jmh233/R-2.14.1/bin/R --no-save < experiment.R
Creating subfolder 11
mkdir: cannot create directory `simulation11': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.168107
[1] 1.368463
[1] 1.381191
[1] 1.264347
[1] 1.123438
[1] 1.007729
[1] 0.9258649
[1] 0.8702761
[1] 0.8319937
[1] 0.8048138
[1] 0.7844862
[1] 0.768434
[1] 0.7552785
[1] 0.7443653
[1] 0.7351309
[1] 0.7276057
[1] 0.7212829
[1] 0.7161553
[1] 0.71225
[1] 1
> 
Creating subfolder 12
mkdir: cannot create directory `simulation12': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.094917
[1] 1.298051
[1] 1.386004
[1] 1.333577
[1] 1.222662
[1] 1.108815
./createFolders.sh: line 4: 30202 Killed                  nice -18 /home/jmh233/R-2.14.1/bin/R --no-save < experiment.R
Creating subfolder 13
mkdir: cannot create directory `simulation13': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.253167
[1] 1.536216
[1] 1.61023
[1] 1.506685
[1] 1.336537
[1] 1.192653
[1] 1.104041
[1] 1.034621
[1] 0.9802891
[1] 0.9367097
[1] 0.9012173
[1] 0.8711705
[1] 0.8451821
[1] 0.8224679
[1] 0.8024609
[1] 0.7844625
[1] 0.7683772
[1] 0.7537464
[1] 0.7399555
[1] 1
> 
Creating subfolder 14
mkdir: cannot create directory `simulation14': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.188456
[1] 1.349179
[1] 1.341555
[1] 1.209189
[1] 1.056101
[1] 0.9308787
[1] 0.841927
[1] 0.7814992
[1] 0.7411318
[1] 0.7135087
[1] 0.6940419
[1] 0.6799911
[1] 0.66984
[1] 0.6616354
[1] 0.6556
[1] 0.6502716
[1] 0.6457582
[1] 0.6419345
[1] 0.6384884
[1] 1
> 
Creating subfolder 15
mkdir: cannot create directory `simulation15': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.193871
[1] 1.395346
[1] 1.360323
[1] 1.210224
[1] 1.05535
[1] 0.9370563
[1] 0.85573
[1] 0.8014024
[1] 0.7642032
[1] 0.7379264
[1] 0.7183271
[1] 0.7033721
[1] 0.691868
[1] 0.6820972
[1] 0.6738331
[1] 0.6667
[1] 0.6600402
[1] 0.6539928
[1] 0.6481275
[1] 1
> 
Creating subfolder 16
mkdir: cannot create directory `simulation16': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.251494
[1] 1.42864
[1] 1.402593
[1] 1.260773
[1] 1.110323
[1] 0.9974621
[1] 0.9169925
[1] 0.8610645
[1] 0.8213692
[1] 0.7916765
[1] 0.7684235
[1] 0.7491074
[1] 0.7324621
[1] 0.7176538
[1] 0.704837
[1] 0.6933039
[1] 0.6827916
[1] 0.6732155
[1] 0.6644335
[1] 1
> 
Creating subfolder 17
mkdir: cannot create directory `simulation17': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.055802
[1] 1.279555
[1] 1.307612
[1] 1.208335
[1] 1.076461
[1] 0.9643039
[1] 0.89742
[1] 0.8489822
[1] 0.8128078
[1] 0.7841558
[1] 0.761339
[1] 0.7426062
[1] 0.7308866
[1] 0.7201557
[1] 0.7103275
[1] 0.7011864
[1] 0.6929018
[1] 0.6855408
[1] 0.6789045
[1] 1
> 
Creating subfolder 18
mkdir: cannot create directory `simulation18': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 0.9506463
[1] 1.138182
[1] 1.156614
[1] 1.069112
[1] 0.9544498
[1] 0.8837362
[1] 0.8282285
[1] 0.7812691
[1] 0.7431021
[1] 0.7124968
[1] 0.6880685
[1] 0.6680704
[1] 0.6516488
[1] 0.6378031
[1] 0.6260832
[1] 0.6200705
[1] 0.6142421
[1] 0.6092805
[1] 0.6042691
[1] 1
> 
Creating subfolder 19
mkdir: cannot create directory `simulation19': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.29332
[1] 1.532294
[1] 1.576696
[1] 1.477137
[1] 1.335046
[1] 1.209261
[1] 1.113992
[1] 1.04517
[1] 0.9932424
[1] 0.9536425
[1] 0.9215431
[1] 0.8940021
[1] 0.8695273
[1] 0.8476185
[1] 0.8278503
[1] 0.8095394
[1] 0.7929041
[1] 0.7771135
[1] 0.762896
[1] 1
> 
Creating subfolder 20
mkdir: cannot create directory `simulation20': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.271124
[1] 1.495329
[1] 1.523349
[1] 1.420904
[1] 1.288841
[1] 1.188466
[1] 1.120122
[1] 1.073978
[1] 1.043766
[1] 1.023338
[1] 1.008684
[1] 0.9975292
[1] 0.9880432
[1] 0.9788512
[1] 0.9704541
[1] 0.962434
[1] 0.9543471
[1] 0.946637
[1] 0.9384702
[1] 1
> 
Creating subfolder 21
mkdir: cannot create directory `simulation21': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 0.9853764
[1] 1.168827
[1] 1.260162
[1] 1.254529
[1] 1.197785
[1] 1.131181
[1] 1.071389
[1] 1.02229
[1] 0.9822568
[1] 0.9491773
[1] 0.9213215
[1] 0.8972994
[1] 0.8761349
[1] 0.8571651
[1] 0.8400434
[1] 0.8247501
[1] 0.8108934
[1] 0.7986824
[1] 0.7878005
[1] 1
> 
Creating subfolder 22
mkdir: cannot create directory `simulation22': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.30359
[1] 1.4384
[1] 1.380757
[1] 1.218758
[1] 1.063491
[1] 0.9501632
[1] 0.8741352
[1] 0.8231508
[1] 0.7879172
[1] 0.7621818
[1] 0.7418961
[1] 0.7250027
[1] 0.7102386
[1] 0.6971088
[1] 0.6850746
[1] 0.6738693
[1] 0.6630602
[1] 0.6526998
[1] 0.6428333
[1] 1
> 
Creating subfolder 23
mkdir: cannot create directory `simulation23': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.22386
[1] 1.415477
[1] 1.408793
[1] 1.296234
[1] 1.147644
[1] 1.017578
[1] 0.9191679
[1] 0.8471391
[1] 0.7947762
[1] 0.755733
[1] 0.7257641
[1] 0.7018294
[1] 0.6821855
[1] 0.6662617
[1] 0.6526954
[1] 0.6415424
[1] 0.6316687
[1] 0.6232865
[1] 0.6156453
[1] 1
> 
Creating subfolder 24
mkdir: cannot create directory `simulation24': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.311275
[1] 1.618579
[1] 1.655998
[1] 1.532179
[1] 1.376765
[1] 1.249579
[1] 1.182099
[1] 1.126326
[1] 1.078199
[1] 1.036656
[1] 1.000759
[1] 0.9707115
[1] 0.9519917
[1] 0.9355121
[1] 0.9213331
[1] 0.9090807
[1] 0.8983295
[1] 0.8890214
[1] 0.8812929
[1] 1
> 
Creating subfolder 25
mkdir: cannot create directory `simulation25': File exists

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> # R script that evaluates the performance of the multitask preference learning model on synthetic data.
> #
> # Author: Jose Miguel Hernandez Lobato
> #
> # Date: 24 Dec 2011
> #
> 
> set.seed(1)
> 
> source("epGPC.R")
> 
> # We eliminate the previous results
> 
> system("rm -f results/*.txt")
> 
> # Number of train/test splits of the data
> 
> nExperiments <- 25
> 
> # We load the simulation number
> 
> simNumber <- read.table("simulationNumber.txt")$V1
> 
> # We repeat for the current train/test partition
> 
> for (i in simNumber) {
+ 
+ 	# We load the item descriptions
+ 
+ 	itemFeatures <- as.matrix(read.table("../../trainTestPartitions/itemFeatures.txt"))
+ 
+ 	# We load the training, pool and test sets
+ 
+ 	train <- as.matrix(read.table(paste("../../trainTestPartitions/train", i, ".txt", sep = "")))
+ 	test <- as.matrix(read.table(paste("../../trainTestPartitions/test", i, ".txt", sep = "")))
+ 	pool <- as.matrix(read.table(paste("../../trainTestPartitions/pool", i, ".txt", sep = "")))
+ 
+ 	# We do 10 iterations of active learning
+ 
+ 	nQueries <- 0
+ 	for (j in 1 : (nQueries + 1)) {
+ 
+ 		# We standardize the item features so that they have zero mean and unit standard deviation in the training set
+ 
+ 		meanItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, mean)
+ 		sdItemFeatures <- apply(itemFeatures[ unique(c(train[ , 1 ], train[ , 2 ])), ], 2, sd)
+ 
+ 		itemFeaturesStandardized <- (itemFeatures - matrix(meanItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)) / 
+ 			matrix(sdItemFeatures, nrow(itemFeatures), ncol(itemFeatures), byrow = T)
+ 
+ 		# We fit a GPC for each userId
+ 
+ 		time <- system.time(gpc <- emBirlutiu(itemFeaturesStandardized, train))
+ 		write.table(time[[ 1 ]] + time[[ 2 ]], paste("results/time", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We eavaluate the performance of the method on the test dataset
+ 
+ 		userIdsTest <- test[ , 3 ]
+ 		ratingsTest <- test[ , 4 ]
+ 
+ 		pred <- rep(0, nrow(test))
+ 		for (k in unique(userIdsTest)) {
+ 			index <- which(userIdsTest == k)
+ 			indexRatings <- mapRatingToIndex(test[ index, 1 ], test[ index, 2 ], nrow(itemFeatures))
+ 			pred[ index ] <- sign(predictGPCbirlutiu(gpc[[ k ]], indexRatings)$m)
+ 		}
+ 
+ 		error <- mean(pred != ratingsTest)
+ 	
+ 		write.table(error, paste("results/error", j - 1, ".txt", sep = ""), col.names = F, row.names = F, append = T)
+ 
+ 		# We make predictions in the pool set
+ 
+ 		userIdsPool <- pool[ , 3 ]
+ 
+ 		toAdd <- c()
+ 		toRemove <- c()
+ 		for (k in unique(userIdsPool)) {
+ 
+ 			index <- which(userIdsPool == k)
+ 			indexRatings <- mapRatingToIndex(pool[ index, 1 ], pool[ index, 2 ], nrow(itemFeatures))
+ 			pred <- predictGPCbirlutiu(gpc[[ k ]], indexRatings)
+ 
+ 			# We evaluate the bald score for each point
+ 
+ 			prob <- pnorm(pred$m / sqrt(pred$v + 1))
+ 			firstTerm <- -(1 - prob) * log(1 - prob) - prob * log(prob)
+ 			C <- sqrt(pi * log(2)  / 2)
+ 			secondTerm <- C / (sqrt(pred$v) + C^2) * exp(-pred$m^2 / (2 * (pred$v + C^2)))
+ 
+ 			bald <- firstTerm - secondTerm
+ 
+ 			# We select the most informative point
+ 
+ 			toAdd <- rbind(toAdd, pool[ index[ which.max(bald) ], ])
+ 			toRemove <- c(toRemove, index[ which.max(bald) ])
+ 		}
+ 
+ 		# We include these items in the train dataset and eliminate them from the pool set
+ 
+ 		train <- rbind(train, toAdd)
+ 		pool <- pool[ -toRemove, ]
+ 
+ 		print(j)
+ 	}
+ }
[1] Inf
[1] 1.332208
[1] 1.512309
[1] 1.443571
[1] 1.25985
[1] 1.080096
[1] 0.9457509
[1] 0.8536893
[1] 0.7910627
[1] 0.7472623
[1] 0.7150485
[1] 0.6904609
[1] 0.6706204
[1] 0.6546685
[1] 0.6414992
[1] 0.6303798
[1] 0.6209847
[1] 0.6131819
[1] 0.6062447
[1] 0.6005383
[1] 1
> 
